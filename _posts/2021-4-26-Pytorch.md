# torch.save

### 后缀格式

[知乎](https://zhuanlan.zhihu.com/p/67053004?from_voters_page=true)

> 首先讲讲保存模型或权重参数的后缀格式，权重参数和模型参数的后缀格式一样，pytorch中最常见的模型保存使用 .pt 或者是 .pth 作为模型文件扩展名。还有其他的保存数据的格式为.t7或者.pkl格式。t7文件是沿用torch7中读取模型权重的方式，而pth文件是python中存储文件的常用格式，而在keras中则是使用.h5文件 。

[腾讯云](https://cloud.tencent.com/developer/article/1507565)

> 要保存多个组件，请在字典中组织它们并使用`torch.save()`来序列化字典。PyTorch 中常见的保存checkpoint 是使用 .tar 文件扩展名。

小结：

保存**模型**用`.pt`

保存**Checkpoint**(包含更多、更完整的信息，用于继续训练)用`.tar`

# 显存

参数量与计算量没有绝对的关系，例如比较fc与conv，前者参数量大，但计算量小，后者参数量小，但计算量大。

谷歌提出的MobileNet就以增大参数量为代价换取更小的计算量（空间换时间），从而提升运行速度。

显存占用 = 模型参数 + 计算产生的中间变量

1. 模型参数

   与输入无关，模型初始化后就固定了

2. 中间变量

   梯度与动量（optimizer反向传播时用到）

# GPU并行下的错误定位

错误如下：
```
/opt/conda/conda-bld/pytorch_1607370172916/work/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:312: operator(): block: [716,0,0], thread: [17,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && "index out of bounds"` failed.

/opt/conda/conda-bld/pytorch_1607370172916/work/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:312: operator(): block: [716,0,0], thread: [28,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && "index out of bounds"` failed.

/opt/conda/conda-bld/pytorch_1607370172916/work/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:312: operator(): block: [291,0,0], thread: [63,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && "index out of bounds"` failed.

CUDA error: device-side assert triggered
```

>在运行命令前加上`CUDA_LAUNCH_BLOCKING=1，强制同步执行，从而显示出正确的错误定位。[参考](https://blog.csdn.net/baoyongshuai1509/article/details/103314145)

> 您可以通过设置环境变量强制进行同步计算 `CUDA_LAUNCH_BLOCKING=1`。这在 GPU 上发生错误时非常方便。(使用异步执行时，直到实际执行操作后才会报告此类错误，因此堆栈跟踪不会显示请求的位置。）[参考](https://pytorch.apachecn.org/docs/1.0/notes_cuda.html#%E5%BC%82%E6%AD%A5%E6%89%A7%E8%A1%8C)

> 当模型在GPU上运行的时候其实是没办法显示出真正导致错误的地方的（按照PyTorch Dev的说法：“Because of the asynchronous nature of cuda, the assert might not point to a full correct stack trace pointing to where the assert was triggered from.”即这是CUDA的特性，他们也没办法），所以可以通过将模型改成在CPU上运行来检查出到底是哪里出错（因为CPU模式下会有更加细致的语法/程序检查）。但是当训练网络特别大的时候，这个方法通常是不可行的，转到CPU上训练的话可能会花费很长时间[1]。[参考](https://www.cnblogs.com/ytxwzqin/p/12012025.html)

本例中真正的错误位置与异步的提示位置差了一行，加上`CUDA_LAUNCH_BLOCKING=1`后，显示了正确的位置。

错误原因是标签(target, gt)中出现了负值，从而导致数组越界。

# nn.Transformer

https://pytorch.org/docs/master/nn.html#transformer-layers

# 设置默认GPU

1. 官方不推荐使用`torch.cuda.set_device(device)`，详见[文档](https://pytorch.org/docs/1.2.0/cuda.html#torch.cuda.set_device)：

> Usage of this function is discouraged in favor of [`device`](https://pytorch.org/docs/1.2.0/cuda.html#torch.cuda.device). In most cases it’s better to use `CUDA_VISIBLE_DEVICES` environmental variable.

2. `torch.cuda.device(device)`：Context-manager that changes the selected device.
3. `os.environ['CUDA_VISIBLE_DEVICES'] = '3'`通过环境变量来设置（**官方推荐**）

尝试后发现：

- **方法1**会在每张GPU上都创建一个进程，仅有实际使用的卡有显存占用，其他卡显存占用0
- **方法3**设置环境变量，一切正常，不会生成额外进程（看来还是要按官方建议来）