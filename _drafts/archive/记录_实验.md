# 1. 多模态

#### mmun

U-Net3

参数设置：

optimizer：Adam，lr=0.0002，weight_decay=0.0005，last 30 epoch decay

loss：Lovasz + Focal(0.1,0.4,0.2,0.3)

iterations=150，epoch=100，patch_size=64，val_idx=0

参数量：**8563652**

原始对照：t1和t2拼接后送入U-net（以下的比较默认都相对于原始对照）

1. 参数量：**14832836**，t1和t2两路编码路径**共享权值**，编码路径各相应层**拼接-卷积压缩**（3x3卷积）后再送入解码路径，仅修改编码路径，对解码路径透明

   过程：训练过程的各项指标几乎**一摸一样**，验证集的CSF抖动非常剧烈，灰质抖动也相对更激烈，白质灰质的整体指标都更差

   最终：训练集一致，验证集Dice要差1~2个点

2. 参数量：**19520900**，修改*1*：t1和t2两路编码路径**不共享权值**，其余不变

   过程：训练过程的各项指标几乎**一摸一样**，验证集抖动稍微更严重点，

   最终：训练集一致，验证集一致（小数级的差距），因此：整体都**比1好**

3. 参数量：，修改*2*：**拼接-卷积压缩**的卷积核大小改为1x1，其余不变

   过程：

   最终：

### MMAN mman 多模态聚合

空洞卷积分别padding=1，2，4，保持输出尺寸一致

用了BN

最近邻上采样

1. 参数量：**316868**，t1t2拼接，送入MMAN（只有一条路），结果相较普通U-Net**差了2个点**
2. 参数量：**625988**，t1t2两条路进去，不共享权值，结果：相较*1*提升（相差）不足1个点，**没有提升**，**最好**
3. 参数量：**623300**，修改*2*：不要**BN**（说明BN层是含有参数的），结果：**性能下降**
4. 参数量：**625988**，修改*2*：上采样改为**双线性**，结果：**没有提升**
5. 参数量：**398948**，修改*2*：两条路共享权值，结果：比*1***差一点**

# 2. 空间信息

### 多轴面ma

U-Net4

三条路对三个轴面进行卷积，卷四层后，~~融合（三条路相加（平均？）），得到空间信息更丰富的特征~~

~~融合后又重新分为三个轴面，进行解码，解码时连接对应轴面的浅层特征~~

对于每一层，将卷积得到的特征图上采样回原尺寸，旋转至同一轴面后，进行**相加**融合，最后再maxpool到那层原本的大小，作为送到上采样路径的特征图

最后在1x1卷积之前，进行融合

1. 第一层**没有旋转回同一轴面**就相加了，结果：每个指标都比U-Net高了**2个点**左右
2. **完善版**，比*1*提升不足**1个点**，几乎差不多（2.1：计算dice时加入smooth=1e-6）
3. 修改*2*，上采样方式改为index maxunpool（反池化时，input要与index的通道数一致），为保持通道数一致，unpool之前进行1x1卷积，更改到与index相同的通道，融合之后再通过1x1卷积还原通道，最后送入上采样路径

两次**换轴面**中间不能有下采样操作，因为特征图尺寸不一致会导致无法**还原轴面**。



### 相邻切片

### 2D+3D

# 3. 边缘

### 注意力机制attention

#### 一、**有监督**注意力模块**sa**

在上采样路径的双卷积前加入注意力模块，经典的**SE结构**？+残差连接？

模块结构为：1x1卷积->relu->1x1卷积->sigmoid->单通道注意力图**am**->相乘->残差连接->输出结果

为am增加一个通道0，*通道1为原通道（注意力）*，两通道之和为1。将am当作一个**二分类**问题进行监督

1. 用**不带权重**的**交叉熵**损失进行监督，结果：相比原始U-Net**无任何提升**
2. 用**不设权重**的**Focal loss**进行监督，结果：相比*1***无任何提升**
3. 根据边界点的像素占比（1/4），设置**Focal loss**权重[0.25 0.75]，结果：相比*1***无任何提升**
4. 用**lovasz softmax**进行监督，结果：相比*1***无任何提升**
5. 改为canny提取边界图em
6. 减少下采样为2次，**训练**结果比*3*差**1个点**，**验证**结果几乎没有提升

对比6次结果：

- 总的来说这6次实验没有明显差距

- *3*的训练结果最好，而验证效果最差：过拟合？

- *6*的训练效果最差，而验证效果最好：对训练集的拟合程度没那么高，反而在一定程度上减轻了过拟合？

输出edge map和attention map，看看是什么样子

#### 二、**无监督**注意力模块nl

添加入non-locl模块（代码来自[cnblogs](https://www.cnblogs.com/pprp/p/12199807.html)），该模块输出与输入尺寸一致。

1. 3层unet（2次下采样），拼接后送入nl模块，得到尺寸一致的输出，再进行上采样阶段的卷积操作。结果：**训练**和**验证**都比基本的4层unet差0.5个点左右
2. 3层unet，nonlocal放在下采样阶段的*卷积之后，下采样之前*，结果：与*1*几乎一致
3. 3层unet，nonlocal放在下采样阶段的*卷积*之前，*池化*之后，结果：与*1*，*2*几乎一致

# 4. 拓扑结构

减少下采样次数，因为尺寸过小的特征图不能很好地保留空间信息，不利于高度依赖空间特征的脑组织分割任务。

# 5. 级联网络

1. [csf]只分脑脊液，看能到达到什么效果